{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis\n",
    "\n",
    "## Intro\n",
    "\n",
    "Whatever the model you want to build in your ML/AI approach you need data. That's where the **Data Science** world emerges!\n",
    "\n",
    "![Fig 1. Relationships.](./ml_docs/data-analysis/images
/intro.png)\n",
    "\n",
    "\n",
    "According to [Wikipedia](https://en.wikipedia.org/wiki/Data_science):\n",
    "\n",
    "\"Data science is an interdisciplinary academic field that uses statistics, scientific computing, scientific methods, processes, algorithms and systems to extract or extrapolate knowledge and insights from noisy, structured, and unstructured data.\"\n",
    "\n",
    "The main idea is to understand the data!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caveats\n",
    "\n",
    "- Data is complex\n",
    "- Sometimes there is no enough data\n",
    "- Sometimes data is too large and resources are too short (CPU, Memory, GPU, TPU, Storage, etc.)\n",
    "- You can have noisy data\n",
    "- Data can be structured or non-structured\n",
    "- Data is unbalanced. You don't always get the right amount of samples\n",
    "- Some data may be hidden\n",
    "\n",
    "The question here is how to get the data that you really need\n",
    "\n",
    "- 80%-90% of the time for building AI/ML solutions is used for understanding and fixing data\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where is the data coming from?\n",
    "\n",
    "- Files and Data bases\n",
    "  - Different formats (CVS, Parquet, Spreadsheets)\n",
    "  - Relational, NoSQL\n",
    "- Real world (i.e. Environment)\n",
    "- Data can be stored previously or can obtained right away (e.g. IoT, Streaming)\n",
    "- Different types:\n",
    "  - Numeric\n",
    "  - Timestamps and dates\n",
    "  - Strings\n",
    "  - Images\n",
    "  - Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is data exactly?\n",
    "\n",
    "- A collection of variables that are correlated\n",
    "- Each variable represents an attribute of a particular sample\n",
    "- Each variable has its own data type\n",
    "- Sometimes these variables are called **features**\n",
    "- How the **features** are expressed determines the _signature_ of the sample\n",
    "\n",
    "### Examples\n",
    "\n",
    "#### Image Recognition\n",
    "\n",
    "- Images with a particular size\n",
    "- Color or gray-scale images\n",
    "- Different objects in the image (Tree, train, auto, etc)\n",
    "- Features: color-palette, contours, edges, shapes, etc.\n",
    "\n",
    "[Fig 2. Deep Learning](./images/dnn01.png)\n",
    "\n",
    "\n",
    "<br>\n",
    "<figure align=\"center\">\n",
    "  <img src = \"images/dnn02.jpg\" width = 80%>\n",
    "      <figcaption style = \"text-align: center; font-style: italic\">Fig 3. Deep Learning.</figcaption>\n",
    "</figure>\n",
    "\n",
    "#### Default and Fraud detection\n",
    "\n",
    "- Demographic information (Age, Sex, Profession, Salary, etc.)\n",
    "- Features: demographic data, number of transactions per month, amount of money per transaction\n",
    "\n",
    "#### More examples\n",
    "\n",
    "- How [Shazam](https://www.shazam.com/) works?\n",
    "  - What are the variables/features that should be analyzed?\n",
    "  - \n",
    "\n",
    "- How to detect drivers under alcohol effects?\n",
    "  - What variables would you use if you are working with image recognition?\n",
    "  - \n",
    "\n",
    "\n",
    "<br>\n",
    "<figure align=\"center\">\n",
    "  <img src = \"images/drunk01.jpg\" width = 60%>\n",
    "      <figcaption style = \"text-align: center; font-style: italic\">Fig 4. Drivers under alcohol effect.</figcaption>\n",
    "</figure>\n",
    "\n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize your data\n",
    "\n",
    "### Do it for variable/feature\n",
    "\n",
    "<br>\n",
    "<figure align=\"center\">\n",
    "  <img src = \"images/visual01.png\" width = 70%>\n",
    "      <figcaption style = \"text-align: center; font-style: italic\">Fig 5. Data Visualization.</figcaption>\n",
    "</figure>\n",
    "\n",
    "### See correlations\n",
    "\n",
    "<br>\n",
    "<figure align=\"center\">\n",
    "  <img src = \"images/visual02.png\" width = 70%>\n",
    "      <figcaption style = \"text-align: center; font-style: italic\">Fig 6. Correlations.</figcaption>\n",
    "</figure>\n",
    "\n",
    "### Apply Basic Statistics\n",
    "\n",
    "- Mean / Average\n",
    "- Variance / Standard Deviation\n",
    "- Distribution\n",
    "- Correlation\n",
    "- Is data discrete or continuous?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning & Transformation\n",
    "\n",
    "- Training a machine learning model depends on good data\n",
    "- If data is poor then the model can produce bad results\n",
    "- Some variables may have different scales\n",
    "\n",
    "### Scenarios\n",
    "\n",
    "Please find below a list of potential cases you may find. All these activities are typical in Data Engineering, Data Enhancement, etc\n",
    "\n",
    "[How Data Preparation works](https://developers.google.com/machine-learning/data-prep/)\n",
    "\n",
    "Case 1: Data may be incomplete\n",
    "\n",
    "- One or more variables/features are absent.\n",
    "- How to fill that gap? What is the best strategy?\n",
    "  - Remove the sample?\n",
    "  - Calculate the average and fill the missing value with the average?\n",
    "  - Drop the feature?\n",
    "\n",
    "<br>\n",
    "<figure align=\"center\">\n",
    "  <img src = \"images/missing.png\" width = 70%>\n",
    "      <figcaption style = \"text-align: center; font-style: italic\">Fig 7. Missing Data.</figcaption>\n",
    "</figure>\n",
    "\n",
    "Case 2: Data contains outliers\n",
    "\n",
    "- Some variables contain too large/small values compared to the rest of the samples\n",
    "  - What is the average salary in a company?\n",
    "  - How this average is affected if you include/exclude the CEO's salary? ¯\\\\\\_(ツ)\\_\\/¯\n",
    "  - What if 5% of the population in a dataset has more than 90 years?\n",
    "\n",
    "<br>\n",
    "<figure align=\"center\">\n",
    "  <img src = \"images/outliers.jpg\" width = 70%>\n",
    "      <figcaption style = \"text-align: center; font-style: italic\">Fig 8. Outliers.</figcaption>\n",
    "</figure>\n",
    "\n",
    "\n",
    "Case 3: Variables/features may have different scales\n",
    "\n",
    "- Age (32, 34, 54, 63, etc) vs Sex (0 if women, 1 if man) \n",
    "- Training a model is \"easier\" if all variables are in the same scale\n",
    "\n",
    "Case 4: Not all variables have the same distribution\n",
    "\n",
    "- Normal distribution?\n",
    "- Should all variables must be normalized?\n",
    "\n",
    "Case 5: Mixed data types\n",
    "- What is more convinient for your ML/AI model?\n",
    "- Can you transform numeric data to categorical data?\n",
    "- Can you do it backbawards? Categorical -> Numeric\n",
    "\n",
    "<br>\n",
    "<figure align=\"center\">\n",
    "  <img src = \"images/binning.jpg\" width = 70%>\n",
    "      <figcaption style = \"text-align: center; font-style: italic\">Fig 9. Data Binning.</figcaption>\n",
    "</figure>\n",
    "\n",
    "Case 6: Meaningless data\n",
    "- Can be removed?\n",
    "  - User ID\n",
    "  - Name of the user\n",
    "- It depends!\n",
    "\n",
    "Case 7: A variable has strong correlation with another variable\n",
    "- Are both variables needed?\n",
    "- Can you remove one variable?\n",
    "\n",
    "Case 8: What if existing features/variables are not enough?\n",
    "- You can create \"synthetic\" variables based on existing variables\n",
    "\n",
    "Case 9: Too much data?\n",
    "- Computational resources are not that big (CPU, Memory, Storage, etc)\n",
    "- Sample data\n",
    "- Make sure that you are sampling the data in the right way\n",
    "- Use scalable Big Data resources\n",
    "  - [BigTable](https://cloud.google.com/bigtable/) and [BigQuery](https://cloud.google.com/bigquery) in Google Cloud Platform (GCP)\n",
    "  - [RedShift](https://aws.amazon.com/redshift) in AWS\n",
    "  - Cloud Storage such as S3 (Aws), Cloud Storage (GCP), Azure Blob Storage (Azure)\n",
    "\n",
    "- In the end, you end up working with massive data where it is necessary to have Datalakes, Warehouses, etc. All these solutions can would help to implement your models whcih can be implemented with technologies such as [Databricks](https://www.databricks.com/) which relies on [Apache Spark](https://spark.apache.org/)\n",
    "\n",
    "\n",
    "\n",
    "### Examples\n",
    "\n",
    "#### Currencies\n",
    "- A bank user can have accounts in several countries and using more than one currency\n",
    "  - Euro\n",
    "  - Colombian Peso, COP\n",
    "  - Mexican Peso, MXN\n",
    "- € 5000 is approx equal to COP $ 22 Million\n",
    "- Training a model for COP may be affected/trained in a different way than a model for Euros\n",
    "- All currencies can be mapped to a standard currency (EUR, USD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
