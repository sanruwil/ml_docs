{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94f0d09b",
   "metadata": {},
   "source": [
    "# Tokenizaci√≥n\n",
    "\n",
    "La tokenizaci√≥n es el proceso de dividir un texto en unidades m√°s peque√±as llamadas tokens. Estos tokens pueden ser palabras, frases, o incluso caracteres, dependiendo del nivel de granularidad deseado.\n",
    "\n",
    "M√©todos Comunes:\n",
    "\n",
    "1. Tokenizaci√≥n de Palabras: \n",
    "Divide el texto en palabras. Ejemplo: \"Hola, ¬øc√≥mo est√°s?\" se convierte en [\"Hola\", \"¬ø\", \"c√≥mo\", \"est√°s\", \"?\"].\n",
    "\n",
    "2. Tokenizaci√≥n de Frases: Divide el texto en frases. Ejemplo: \"Hoy es un buen d√≠a.\" se convierte en [\"Hoy es un buen d√≠a.\"].\n",
    "\n",
    "3. Tokenizaci√≥n de Caracteres: Divide el texto en caracteres. Ejemplo: \"Hola\" se convierte en [\"H\", \"o\", \"l\", \"a\"].\n",
    "\n",
    "conda install anaconda::nltk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6e77e9",
   "metadata": {},
   "source": [
    "Tokenizacion\n",
    "NLP: https://www.nltk.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "597fea11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hola', '¬øc√≥mo', 'est√°s', '?']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/wilfredysantamariaruiz/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "texto = \"Hola ¬øc√≥mo est√°s?\"\n",
    "tokens = word_tokenize(texto)\n",
    "print(tokens)\n",
    "# Salida: ['Hola', ',', '¬ø', 'c√≥mo', 'est√°s', '?']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d6d86f",
   "metadata": {},
   "source": [
    "Paso 1: Tokenizaci√≥n\n",
    "Primero, tokenizamos el documento:\n",
    "\n",
    "Documento: \"Hola ¬øc√≥mo est√°s?\"\n",
    "Tokens: [\"Hola\", \"¬ø\", \"c√≥mo\", \"est√°s\", \"?\"]\n",
    "Vamos a considerar solo las palabras significativas para el c√°lculo de TF-IDF, omitiendo los signos de puntuaci√≥n y stop words. Para simplificar, usaremos [\"Hola\", \"c√≥mo\", \"est√°s\"].\n",
    "\n",
    "Paso 2: Calcular TF (Term Frequency)\n",
    "La frecuencia de t√©rminos (TF) se calcula como el n√∫mero de veces que una palabra aparece en el documento dividido por el n√∫mero total de palabras en el documento.\n",
    "\n",
    "Para cada palabra en \n",
    "D1:\n",
    "\n",
    "TF(\"Hola\"): 1/3\n",
    "TF(\"c√≥mo\"): 1/3\n",
    "TF(\"est√°s\"): 1/3\n",
    "Paso 3: Calcular IDF (Inverse Document Frequency)\n",
    "La frecuencia inversa de documentos (IDF) se calcula como el logaritmo del n√∫mero total de documentos en el corpus dividido por el n√∫mero de documentos que contienen el t√©rmino.\n",
    "\n",
    "Supongamos que \n",
    "\n",
    "D1 es el √∫nico documento en el corpus. Para cada palabra en \n",
    "\n",
    "N√∫mero total de documentos (N): 1\n",
    "Documentos que contienen \"Hola\" (df(\"Hola\")): 1\n",
    "Documentos que contienen \"c√≥mo\" (df(\"c√≥mo\")): 1\n",
    "Documentos que contienen \"est√°s\" (df(\"est√°s\")): 1\n",
    "IDF se calcula como:\n",
    "\n",
    "IDF(t)=log( N/df(t))+1\n",
    "\n",
    "A√±adimos 1 al logaritmo para evitar divisiones por cero.\n",
    "\n",
    "IDF(\"Hola\"): log(1/1))+1=1\n",
    "IDF(\"c√≥mo\"): log(1/1))+1=1\n",
    "IDF(\"est√°s\"): log(1/1))+1=1\n",
    "\n",
    "Paso 4: Calcular TF-IDF\n",
    "TF-IDF se calcula multiplicando TF y IDF para cada palabra.\n",
    "\n",
    "Para cada palabra en \n",
    "D1:\n",
    "TF-IDF(\"Hola\"): (1/3)√ó1=1/3‚âà0.333\n",
    "\n",
    "TF-IDF(\"c√≥mo\"): (1/3)√ó1=1/3‚âà0.333\n",
    "\n",
    "TF-IDF(\"est√°s\"): (1/3)√ó1=1/3‚âà0.333\n",
    "\n",
    "Normalizaci√≥n (Vector de Caracter√≠sticas)\n",
    "Para vectorizar el documento y usarlo en algoritmos de aprendizaje autom√°tico, los valores TF-IDF se normalizan para que el vector tenga una longitud unitaria.\n",
    "\n",
    "El vector TF-IDF para D1:\n",
    "\n",
    "TF-IDF(D1)=[0.333,0.333,0.333]\n",
    "\n",
    "La normalizaci√≥n se realiza dividiendo cada componente del vector por la norma ùêø2\n",
    "\n",
    "L2 (longitud) del vector:\n",
    "\n",
    "norma(D1)= sqtr((0.33)*2  +((0.33)*2)+ ((0.33)*2))= sqtr(3* 0.11)  ‚âà0.577\n",
    "\n",
    "Vector normalizado:\n",
    "\n",
    "TF-IDF¬†normalizado\n",
    "ùê∑1=(0.333/0.577, 0.333/0.577,0.333/0.577)\n",
    "D1=[0.577,0.577,0.577]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a9303e",
   "metadata": {},
   "source": [
    "**Vectorizaci√≥n con TF-IDF:**\n",
    "\n",
    "La vectorizaci√≥n es el proceso de convertir los tokens (o textos) en vectores num√©ricos que los algoritmos de machine learning pueden utilizar. Es esencial para transformar datos textuales en formatos adecuados para modelos matem√°ticos y computacionales.\n",
    "\n",
    "M√©todos Comunes:\n",
    "\n",
    "\n",
    "1. Bag of Words (BoW): Representa el texto como una matriz de frecuencia de palabras. \n",
    "\n",
    "Texto: \"Hola, ¬øc√≥mo est√°s?\"\n",
    "\n",
    "BoW: {\"Hola\": 1, \"c√≥mo\": 1, \"est√°s\": 1}\n",
    "\n",
    "2. TF-IDF (Term Frequency-Inverse Document Frequency): Ajusta la frecuencia de las palabras considerando su relevancia en el corpus completo. \n",
    "\n",
    "Texto: \"Hola, ¬øc√≥mo est√°s?\"\n",
    "\n",
    "TF-IDF: {\"Hola\": 0.5, \"c√≥mo\": 0.7, \"est√°s\": 0.3}\n",
    "\n",
    "3. Word Embeddings: Representa palabras en un espacio continuo de alta dimensi√≥n. \n",
    "\n",
    "\"Hola\" -> [0.1, 0.2, 0.3], \"c√≥mo\" -> [0.4, 0.5, 0.6]\n",
    "\n",
    "4. Modelos Preentrenados: Utiliza embeddings generados por modelos como BERT, GPT, etc. \n",
    "\n",
    "\"Hola\" -> [vector de 768 dimensiones], \"c√≥mo\" -> [vector de 768 dimensiones]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bdc2b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.57735027 0.57735027 0.57735027]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "corpus = [texto]\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(X.toarray())\n",
    "# Salida: [array de valores TF-IDF]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29d20fa",
   "metadata": {},
   "source": [
    "sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5f4ae06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caracter√≠sticas (Palabras): ['c√≥mo' 'est√°s' 'hola']\n",
      "Arreglo TF-IDF:\n",
      "[[0.57735027 0.57735027 0.57735027]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "# Documentos de ejemplo\n",
    "D1 = \"Hola ¬øc√≥mo est√°s?\"\n",
    "#D2 = \"Estoy bien, gracias.\"\n",
    "#D3 = \"Hola, ¬øc√≥mo te sientes hoy?\"\n",
    "\n",
    "# Crear un corpus con los documentos\n",
    "#corpus = [D1, D2, D3]\n",
    "corpus = [D1]\n",
    "\n",
    "\n",
    "# Inicializar el vectorizador TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Ajustar y transformar el corpus\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Convertir la matriz TF-IDF a un arreglo denso\n",
    "tfidf_array = X.toarray()\n",
    "\n",
    "# Obtener los nombres de las caracter√≠sticas (palabras)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(\"Caracter√≠sticas (Palabras):\", feature_names)\n",
    "print(\"Arreglo TF-IDF:\")\n",
    "print(tfidf_array)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8940c97b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
